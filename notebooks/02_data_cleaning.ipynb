{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a629edb-694b-4608-bc43-71eb19646da6",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75a7d19-59ce-4e58-a288-67d8894490b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'analyze_missing_values' from 'src.data.clean_data' (/Users/rexcoleman/Documents/DataScienceAndMachineLearning/Rex_Coleman_Machine_Learning_Cybersecurity_Portfolio/Microsoft_Malware_Prediction_Project/src/data/clean_data.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Add the parent directory to sys.path\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclean_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m handle_missing_values, remove_duplicates, analyze_missing_values, compute_correlations, visualize_distributions\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_csv_with_progress\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_clean_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_no_missing_values, check_no_duplicates\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'analyze_missing_values' from 'src.data.clean_data' (/Users/rexcoleman/Documents/DataScienceAndMachineLearning/Rex_Coleman_Machine_Learning_Cybersecurity_Portfolio/Microsoft_Malware_Prediction_Project/src/data/clean_data.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.data.clean_data import handle_missing_values, remove_duplicates, analyze_missing_values, compute_correlations, visualize_distributions\n",
    "from src.data.load_data import read_csv_with_progress\n",
    "from src.tests.test_clean_data import check_no_missing_values, check_no_duplicates\n",
    "from src.config_loader import paths_config, dtypes_config\n",
    "\n",
    "# Load the data\n",
    "file_path = paths_config['paths']['processed_data'] + 'train_explored.csv'\n",
    "df = read_csv_with_progress(file_path, dtypes=dtypes_config['dtypes'])\n",
    "\n",
    "# Analyze missing values\n",
    "missing_data = analyze_missing_values(df)\n",
    "print(missing_data.head(20))\n",
    "\n",
    "# Visualize distributions of features with the most missing values\n",
    "top_missing_features = missing_data.head(10).index.tolist()\n",
    "visualize_distributions(df, top_missing_features)\n",
    "\n",
    "# Compute correlations with the target variable\n",
    "correlations = compute_correlations(df, 'HasDetections')\n",
    "print(correlations.head(20))\n",
    "\n",
    "# Handle missing values (example strategy)\n",
    "df = handle_missing_values(df)\n",
    "\n",
    "# Remove duplicates\n",
    "df = remove_duplicates(df, 'MachineIdentifier')\n",
    "\n",
    "# Perform tests\n",
    "print(check_no_missing_values(df))  # Should print True\n",
    "print(check_no_duplicates(df, 'MachineIdentifier'))  # Should print True\n",
    "\n",
    "# Save the cleaned dataframe for subsequent steps\n",
    "chunk_size = 100000\n",
    "num_chunks = len(df) // chunk_size + 1\n",
    "\n",
    "with tqdm(total=num_chunks, desc=\"Saving cleaned CSV in chunks\") as pbar:\n",
    "    for i, start in enumerate(range(0, len(df), chunk_size)):\n",
    "        end = start + chunk_size\n",
    "        df[start:end].to_csv(paths_config['paths']['processed_data'] + 'train_cleaned.csv', mode='a', index=False, header=(i==0))\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3ec20-ea34-41f7-9256-efbe4baf8402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85a361-1684-4db5-8a4c-0daebfcdece5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de9b28-9c39-4e3f-a753-b0a53e387a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be13d2b-d682-4cce-beda-3f1251d1167a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc615b37-034e-4685-a513-33903bf11685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942a517c20604f7babfffb48d0134514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading CSV in chunks:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 60686127 missing values.\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4de7a209ba5436ba1a05404965e0909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving cleaned CSV in chunks:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.data.clean_data import handle_missing_values, remove_duplicates\n",
    "from src.tests.test_clean_data import check_no_missing_values, check_no_duplicates\n",
    "from src.data.load_data import read_csv_with_progress, load_dtypes_from_yaml, read_config\n",
    "\n",
    "# Load configuration\n",
    "config = read_config()\n",
    "file_path = config['paths']['processed_data'] + 'train_explored.csv'\n",
    "\n",
    "# Load the data\n",
    "df = read_csv_with_progress(file_path)\n",
    "\n",
    "# Handle missing values\n",
    "df = handle_missing_values(df)\n",
    "\n",
    "# Remove duplicates\n",
    "df = remove_duplicates(df, 'MachineIdentifier')\n",
    "\n",
    "# Perform tests\n",
    "print(check_no_missing_values(df))  # Should print True\n",
    "print(check_no_duplicates(df, 'MachineIdentifier'))  # Should print True\n",
    "\n",
    "# Save the cleaned dataframe for subsequent steps\n",
    "chunk_size = 100000\n",
    "num_chunks = len(df) // chunk_size + 1\n",
    "\n",
    "with tqdm(total=num_chunks, desc=\"Saving cleaned CSV in chunks\") as pbar:\n",
    "    for i, start in enumerate(range(0, len(df), chunk_size)):\n",
    "        end = start + chunk_size\n",
    "        df[start:end].to_csv(config['paths']['processed_data'] + 'train_cleaned.csv', mode='a', index=False, header=(i==0))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7729e7-95b4-442d-9256-290ebb896541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3fa67-77c9-4675-a1fb-23239c496ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.data.clean_data import handle_missing_values, remove_duplicates\n",
    "from src.tests.test_clean_data import check_no_missing_values, check_no_duplicates\n",
    "from src.data.load_data import read_csv_with_progress, load_dtypes_from_yaml, read_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f5eae-f022-4c4b-8713-cacb670038ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = read_config()\n",
    "file_path = config['paths']['processed_data'] + 'train_explored.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2db75-e0eb-4149-8678-0da1e3288938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = read_csv_with_progress(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb003434-328f-467a-8ea3-3e83e83a51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile missing values\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"Missing values in each column:\\n\", missing_values.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a83f6-0604-47d1-a66c-f68ce2ffee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the missing values profile to a CSV for detailed analysis\n",
    "missing_values.to_csv(config['paths']['processed_data'] + 'missing_values_profile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7abe13-4835-45e5-853d-303b46008169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df = handle_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7018ab-2198-4e5e-a634-862ddc79a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = remove_duplicates(df, 'MachineIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2dd77e-73b7-40b1-9193-019542837684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleaning steps can be added here, such as removing or imputing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835776d9-7b6c-4af6-8e47-04dd87a56609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform tests\n",
    "print(check_no_missing_values(df))  # Should print True\n",
    "print(check_no_duplicates(df, 'MachineIdentifier'))  # Should print True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f872385-fe0d-4dfd-9145-be6b1286a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataframe for subsequent steps\n",
    "chunk_size = 100000\n",
    "num_chunks = len(df) // chunk_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db3971-6356-4f4c-af57-0e0c2909792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=num_chunks, desc=\"Saving cleaned CSV in chunks\") as pbar:\n",
    "    for i, start in enumerate(range(0, len(df), chunk_size)):\n",
    "        end = start + chunk_size\n",
    "        df[start:end].to_csv(config['paths']['processed_data'] + 'train_cleaned.csv', mode='a', index=False, header=(i==0))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf08ab-ef0e-4fd8-bc21-7dfc1b6762ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
