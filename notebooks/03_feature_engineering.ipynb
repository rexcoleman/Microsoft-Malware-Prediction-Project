{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a2451d-ea8d-4110-929e-773026bf9730",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f4869-02c4-48f6-b09d-737ba14e7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from src.features.build_features import create_interaction_features, scale_features\n",
    "from src.tests.test_features import check_interaction_features, check_scaled_features\n",
    "from src.config_loader import paths_config\n",
    "\n",
    "# Define the features to scale\n",
    "features_to_scale = ['feature1', 'feature2']  # Replace with actual feature names\n",
    "\n",
    "# Load the processed data\n",
    "file_path = os.path.join(paths_config['paths']['processed_data'], 'train_cleaned.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Capture the original columns before creating interaction features\n",
    "original_columns = df.columns.tolist()\n",
    "\n",
    "# Create interaction features with progress bar\n",
    "df = create_interaction_features(df)\n",
    "df.head()\n",
    "\n",
    "# Define the expected interaction columns (example, replace with actual expected columns)\n",
    "interaction_columns = ['interaction_feature1', 'interaction_feature2']  # Replace with actual interaction feature names\n",
    "\n",
    "# Perform tests on interaction features\n",
    "print(check_interaction_features(df, original_columns, interaction_columns))\n",
    "\n",
    "# Select features to scale\n",
    "df = scale_features(df, features_to_scale)\n",
    "df.head()\n",
    "\n",
    "# Perform tests on scaled features\n",
    "print(check_scaled_features(df, features_to_scale))\n",
    "\n",
    "# Save the dataframe in chunks with a progress bar\n",
    "chunk_size = 100000\n",
    "num_chunks = len(df) // chunk_size + 1\n",
    "\n",
    "output_path = os.path.join(paths_config['paths']['processed_data'], 'train_featured.csv')\n",
    "with tqdm(total=num_chunks, desc=\"Saving CSV in chunks\") as pbar:\n",
    "    for i, start in enumerate(range(0, len(df), chunk_size)):\n",
    "        end = start + chunk_size\n",
    "        df[start:end].to_csv(output_path, mode='a', index=False, header=(i==0))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942bea4-1456-46c6-b5b3-2ae2807599ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e9f85-65fe-40b2-98df-ab62a02fbe9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a255c5-1dcd-4838-b3e7-2fe725238513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d8b42-194e-4862-80df-c90a701d6132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a762de-be16-4452-be4a-008242c91b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca249c8-11be-45df-9b7b-043c60fa0d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba34291-1655-41b6-a98a-bee2086c9188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017985d-a2ea-40ac-af3c-37442b5721b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import pandas as pd\n",
    "from src.features.build_features import create_interaction_features, scale_features\n",
    "from src.tests.test_features import check_interaction_features, check_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc37653-6b0b-41a0-9e5f-65d741504f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features to scale\n",
    "features_to_scale = ['feature1', 'feature2']  # Replace with actual feature names\n",
    "\n",
    "# Load the processed data\n",
    "file_path = '../data/processed/train_cleaned.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cac539-bd9b-40de-8499-737cda5236be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the original columns before creating interaction features\n",
    "original_columns = df.columns.tolist()\n",
    "\n",
    "# Create interaction features with progress bar\n",
    "df = create_interaction_features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e388d-6b31-4750-971a-1d711ee98608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the expected interaction columns (example, replace with actual expected columns)\n",
    "interaction_columns = ['interaction_feature1', 'interaction_feature2']  # Replace with actual interaction feature names\n",
    "\n",
    "# Perform tests on interaction features\n",
    "print(check_interaction_features(df, original_columns, interaction_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54bd0f4-7af9-475f-b7c4-e666fe1c9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features to scale\n",
    "df = scale_features(df, features_to_scale)\n",
    "df.head()\n",
    "\n",
    "# Perform tests on scaled features\n",
    "print(check_scaled_features(df, features_to_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a219cbd3-7697-4040-86e2-8559a0bb77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe in chunks with a progress bar\n",
    "chunk_size = 100000\n",
    "num_chunks = len(df) // chunk_size + 1\n",
    "\n",
    "with tqdm(total=num_chunks, desc=\"Saving CSV in chunks\") as pbar:\n",
    "    for i, start in enumerate(range(0, len(df), chunk_size)):\n",
    "        end = start + chunk_size\n",
    "        df[start:end].to_csv('../data/processed/train_featured.csv', mode='a', index=False, header=(i==0))\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
