import pandas as pd
import dask.dataframe as dd
from tqdm.notebook import tqdm
import logging
import os
import yaml

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_data(file_path, dtypes, use_dask=False, chunk_size=100000):
    """
    Load data from a CSV file with a progress bar.
    
    Parameters:
    - file_path: str, path to the CSV file.
    - dtypes: dict, dictionary specifying data types.
    - use_dask: bool, whether to use dask for large data files.
    - chunk_size: int, size of chunks to read at a time.
    
    Returns:
    - DataFrame: loaded data.
    """
    if use_dask:
        df = dd.read_csv(file_path, dtype=dtypes).compute()
    else:
        total_rows = sum(1 for _ in open(file_path)) - 1  # Total number of rows minus the header
        num_chunks = total_rows // chunk_size + 1

        df = pd.DataFrame()
        with tqdm(total=num_chunks, desc="Loading CSV in chunks") as pbar:
            for chunk in pd.read_csv(file_path, chunksize=chunk_size, dtype=dtypes, low_memory=False):
                df = pd.concat([df, chunk], ignore_index=True)
                pbar.update(1)
        logging.info(f'Successfully loaded data from {file_path}')
    return df

def read_config(config_path='../config.yaml'):
    """
    Read configuration from a YAML file.
    
    Parameters:
    - config_path: str, path to the configuration YAML file.
    
    Returns:
    - dict: configuration parameters.
    """
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

if __name__ == "__main__":
    config = read_config()
    file_path = config['paths']['raw_data']
    dtypes = config['dtypes']
    df = load_data(file_path, dtypes, use_dask=True)
    print(df.head())
